{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KHARMA Tutorial \n",
    "# CCA Numerical Series on Fluids and Plasmas (10/24/2024)\n",
    "---\n",
    "---\n",
    "\n",
    "## Getting KHARMA\n",
    "\n",
    "KHARMA can be found on Github [here](https://github.com/AFD-Illinois/kharma).\n",
    "For this tutorial we'll be working with the `tutorial` branch which can be cloned like,\n",
    "\n",
    "`git clone -b tutorial https://github.com/AFD-Illinois/kharma.git`\n",
    "\n",
    "---\n",
    "\n",
    "## Building pyharm\n",
    "\n",
    "Additionally, we'll need `pyharm`, a Python package for analyzing GRMHD data products from HARM-based codes. The code is hosted [here](https://github.com/AFD-Illinois/pyharm), and can be obtained using git,\n",
    "\n",
    "`git clone https://github.com/AFD-Illinois/pyharm.git`\n",
    "\n",
    "It's generally good practice to isolate Python environments when working on different projects to avoid dependency hell. Also, the SCC at FI won't let us install python packages on the Python moduel provided by them. Let's download the python module (if you don't have it by default in your module stack), set up a virtual environment, and install `pyharm`,\n",
    "\n",
    "```\n",
    "module load python3\n",
    "VENVDIR=PATH_WHERE_PYTHON_VENVS_ARE_STORED\n",
    "python3 -m venv --system-site-packages $VENVDIR/pyharm\n",
    "source $VENVDIR/pyharm/bin/activate\n",
    "cd pyharm\n",
    "pip3 install -e .\n",
    "```\n",
    "where, `VENVDIR` is the location where you would want to save your Python environments; for this tutorial we've created a virtual enviroment `pyharm`. More about Python virtual environments on Rusty [here](https://wiki.flatironinstitute.org/SCC/Software/PythonVirtualEnvironments). \n",
    "\n",
    "If you instead prefer working with `conda`, `pyharm` has a `environment.yml` file that can be used to set up an environment with `conda`. More about that [here](https://pyharm.readthedocs.io/en/latest/installing.html).\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building KHARMA\n",
    "\n",
    "KHARMA has two main dependencies which must be checked out before compiling it,\n",
    "```\n",
    "cd kharma\n",
    "git submodule update --init --recursive\n",
    "```\n",
    "\n",
    "KHARMA has an extensive [wiki](https://github.com/AFD-Illinois/kharma/wiki) and lists the minimum requirements needed. Let us set up the module environment needed to compile KHARMA for GPUs on Rusty,\n",
    "\n",
    "```\n",
    "module load modules/2.3-20240529 slurm cmake gcc/11.4.0 cuda gsl openmpi hdf5 openblas\n",
    "```\n",
    "For CPUs, it's nearly the same, except we don't need the `cuda` module. \n",
    "\n",
    "KHARMA uses `cmake` to build the code called from the `make` shell script. This script in conjuction with machine-specific build files are help set up the module environment and pass necessary arguments to `cmake`. By default KHARMA parallelizes the build process, and therefore it is good practice to compile KHARMA on a compute node. To get an interactive session on a compute node on Rusty try,\n",
    "\n",
    "`srun -N 1 --constraint=ib-icelake --pty bash -i`\n",
    "\n",
    "To run KHARMA on NVIDIA A100s use the following command,\n",
    "\n",
    "`./make.sh clean cuda a100`\n",
    "\n",
    "The `cuda` argument tells Kokkos to build with CUDA, while the `a100` argument specifies the device architecture. KHARMA's build philosophy is to have separate machine-specific files that setup the relevant module environment and environment variables, e.g., there is a machine config file for Rusty (`machines/rusty.sh`) that builds for different architectures available on Rusty.\n",
    "\n",
    "If you'd like to build for KHARMA to be run on CPU, say the icelake nodes, the build command would be,\n",
    "\n",
    "`./make.sh clean skx`.\n",
    "\n",
    "At the end, you should see the following output on the screen that comfirms KHARMA was built successfully,\n",
    "\n",
    "![gpu build](images/screenshot_gpu_build.png)\n",
    "\n",
    "OR\n",
    "\n",
    "![cpu build](images/screenshot_cpu_build.png)\n",
    "\n",
    "depending on the type of build. The postfix (`.cuda`, `.host`) in the executable name specifies the architecture KHARMA was built for. More about compiling [here](https://github.com/AFD-Illinois/kharma/wiki/Building-KHARMA).\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running KHARMA\n",
    "\n",
    "KHARMA can either be run in broadly two ways,\n",
    "- By directly calliing the executable: `./kharma.host -i PROBLEM_PARAMETER_FILE`. This works best when you are running on a personal computer or are on a compute node via an interactive job, and have manually set the module stack and required environment variables correctly.\n",
    "\n",
    "- Invoking `run.sh` or a batch script: Often, we don't want to manually set the environment and want the runtime environment to be set automatically based on the compile-time options. This is where `run.sh` or a machine-specific batch script comes in.\n",
    "\n",
    "For this tutorial we'll use the slurm batch scripts located in the `scripts/tutorial/batch` directory. This script sets the SLURM directives, sources the machine file to set the module environment, and submits the job."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Pressure equilibrium in ideal MHD\n",
    "\n",
    "It is good practice to create a separate directory for each problem run; say `SIMULATION_DIR` is where we'll run the first problem. KHARMA will output data to the directory where the executable is called from. Let's run the following set of commands,\n",
    "\n",
    "```\n",
    "cd SIMULATION_DIR\n",
    "cp PATH_TO_KHARMA_SOURCE/scripts/tutorial/batch/rusty_gpu.sb ./\n",
    "cp PATH_TO_KHARMA_SOURCE/scripts/tutorial/parfiles/anisotropic_conduction_ideal.par ./\n",
    "```\n",
    "This copies over the job submit script and the parameter file for the problem to `SIMULAITON_DIR`. Before we move on to running the problem, let's take a look at the parameter file.\n",
    "\n",
    "KHARMA was designed from ground up with flexibility and extensibility in mind; most parameters are therefore runtime. This means the number of parameters is [long and growing](https://github.com/AFD-Illinois/kharma/wiki/Parameters). However, on a day-to-day basis there are only a limited number of parameters that you'd need to modify depending on the problem and KHARMA sets sensible default values for the rest.\n",
    "Parameters are divided into blocks and are specified like `block_name/parameter_name=value`. Let's take a look at the parameter file for this problem to see this in practice.\n",
    "\n",
    "Now, let's submit the job\n",
    "\n",
    "`sbatch rusty_gpu.sb -i anisotropic_conduction_ideal.par`\n",
    "\n",
    "In this case we explicitly ask Parthenon (via the `-d` flag in the job submit script) to create the save output (dump files, restart files, etc..) in a separate directory `dumps_kharma`. We could have pointed to the parameter file at `PATH_TO_KHARMA_SOURCE/scripts/tutorial/parfiles/` but it is cleaner this way---each simulation has its own copy of the parameter file and we avoid changing the defaults in the git repository."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations on running your first KHARMA simulation!**\n",
    "\n",
    "Let's take a look at the output. The standard output is saved to the `.out` file. When the problem is executing, you'll see a line like this (for explicitly-evolved problems at least),\n",
    "\n",
    "```\n",
    "cycle=50 time=6.0457029249727713e-02 dt=1.4976930529853696e-03 zone-cycles/wsec_step=4.24e+07 wsec_total=4.25e-01 wsec_step=6.18e-03\n",
    "Max DivB: 1.52656e-16\n",
    "```\n",
    "`cycle` denotes the timestep number, `time` is the simulation time in code units (e.g., for a black hole accretion problem it'd be in units of the light-crossing time $GM/c^3$), `dt` is the size of the timestep, and `zone-cycles/wsec_step` is the number of zone cycle per second.\n",
    "\n",
    "The simulation output is saved to `dump_kharma`. Files ending with `phdf` are the fluid \"dump\" files and stores the state of the fluid at a given time. Restart files have the `rhdf` extensions.\n",
    "\n",
    "It is most convenient to use `pyharm` to work with KHARMA output. At the heart of `pyharm` is the FluidDump object that caches the data in the dump file, and computes derived quantities from the cached data on-the-fly. It acts like a Python dictionary from which various quantities (related to the fluid state, grid, input parameters, etc..) can be accessed by passing the right key. The `load_dump` method is used to obtain the fluid state object. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyharm\n",
    "import matplotib.pyplot as plt\n",
    "\n",
    "dump = pyharm.load_dump(os.path.join(dumpsdir, 'anisotropic_conduction.out0.00000.phdf'))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax  = fig.gca()\n",
    "ax.pcolormesh(np.squeeze(dump['X1']), np.squeeze(dump['X2']), np.squeeze(dump['Theta']), cmap = 'viridis', shading='gouraud')\n",
    "ax.set_xlim(0,1)\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_xticks([0,0.25,0.5,0.75,1])\n",
    "ax.set_xticklabels([0,0.25,0.5,0.75,1])\n",
    "ax.set_yticks([0,0.25,0.5,0.75,1])\n",
    "ax.set_yticklabels([0,0.25,0.5,0.75,1])\n",
    "ax.set_xlabel('$x (GM/c^2)$')\n",
    "ax.set_ylabel('$y (GM/c^2)$')\n",
    "ax.set_aspect('equal')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "cbar = plt.colorbar(temp_plot, cax=cax)\n",
    "cbar.set_label('P$_{g}/\\\\rho$', rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
