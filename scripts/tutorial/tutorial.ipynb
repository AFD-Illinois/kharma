{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KHARMA Tutorial \n",
    "# CCA Numerical Series on Fluids and Plasmas (10/24/2024)\n",
    "---\n",
    "---\n",
    "\n",
    "## PREREQUISITES\n",
    "\n",
    "### Getting KHARMA\n",
    "\n",
    "KHARMA can be found on Github [here](https://github.com/AFD-Illinois/kharma).\n",
    "For this tutorial we'll be working with the `tutorial` branch which can be cloned like,\n",
    "\n",
    "`git clone -b tutorial https://github.com/AFD-Illinois/kharma.git`\n",
    "\n",
    "---\n",
    "\n",
    "### Building pyharm\n",
    "\n",
    "Additionally, we'll need `pyharm`, a Python package for analyzing GRMHD data products from HARM-based codes. The code is hosted [here](https://github.com/AFD-Illinois/pyharm), and can be obtained using git,\n",
    "\n",
    "`git clone https://github.com/AFD-Illinois/pyharm.git`\n",
    "\n",
    "It's generally good practice to isolate Python environments when working on different projects to avoid dependency hell. Also, the SCC at FI won't let us install python packages on the Python moduel provided by them. Let's download the python module (if you don't have it by default in your module stack), set up a virtual environment, and install `pyharm`,\n",
    "\n",
    "```\n",
    "module load python3\n",
    "VENVDIR=PATH_WHERE_PYTHON_VENVS_ARE_STORED\n",
    "python3 -m venv --system-site-packages $VENVDIR/pyharm\n",
    "source $VENVDIR/pyharm/bin/activate\n",
    "cd pyharm\n",
    "pip3 install -e .\n",
    "```\n",
    "where, `VENVDIR` is the location where you would want to save your Python environments; for this tutorial we've created a virtual enviroment `pyharm`. More about Python virtual environments on Rusty [here](https://wiki.flatironinstitute.org/SCC/Software/PythonVirtualEnvironments). \n",
    "\n",
    "If you instead prefer working with `conda`, `pyharm` has a `environment.yml` file that can be used to set up an environment with `conda`. More about that [here](https://pyharm.readthedocs.io/en/latest/installing.html).\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building KHARMA\n",
    "\n",
    "KHARMA has two main dependencies which must be checked out before compiling it,\n",
    "```\n",
    "cd kharma\n",
    "git submodule update --init --recursive\n",
    "```\n",
    "\n",
    "KHARMA has an extensive [wiki](https://github.com/AFD-Illinois/kharma/wiki) and lists the minimum requirements needed. Let us set up the module environment needed to compile KHARMA for GPUs on Rusty,\n",
    "\n",
    "```\n",
    "module load modules/2.3-20240529 slurm cmake gcc/11.4.0 cuda gsl openmpi hdf5 openblas\n",
    "```\n",
    "For CPUs, it's nearly the same, except we don't need the `cuda` module. \n",
    "\n",
    "KHARMA uses `cmake` to build the code called from the `make` shell script. This script in conjuction with machine-specific build files are help set up the module environment and pass necessary arguments to `cmake`. By default KHARMA parallelizes the build process, and therefore it is good practice to compile KHARMA on a compute node. To get an interactive session on a compute node on Rusty try,\n",
    "\n",
    "`srun -N 1 --constraint=ib-icelake --pty bash -i`\n",
    "\n",
    "To run KHARMA on NVIDIA A100s use the following command,\n",
    "\n",
    "`./make.sh clean cuda a100`\n",
    "\n",
    "The `cuda` argument tells Kokkos to build with CUDA, while the `a100` argument specifies the device architecture. KHARMA's build philosophy is to have separate machine-specific files that setup the relevant module environment and environment variables, e.g., there is a machine config file for Rusty (`machines/rusty.sh`) that builds for different architectures available on Rusty.\n",
    "\n",
    "If you'd like to build for KHARMA to be run on CPU, say the icelake nodes, the build command would be,\n",
    "\n",
    "`./make.sh clean skx`.\n",
    "\n",
    "At the end, you should see the following output on the screen that comfirms KHARMA was built successfully,\n",
    "\n",
    "![gpu build](images/screenshot_gpu_build.png)\n",
    "\n",
    "OR\n",
    "\n",
    "![cpu build](images/screenshot_cpu_build.png)\n",
    "\n",
    "depending on the type of build. The postfix (`.cuda`, `.host`) in the executable name specifies the architecture KHARMA was built for. More about compiling [here](https://github.com/AFD-Illinois/kharma/wiki/Building-KHARMA).\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running KHARMA\n",
    "\n",
    "KHARMA can either be run in broadly two ways,\n",
    "- By directly calliing the executable: `./kharma.host -i PROBLEM_PARAMETER_FILE`. This works best when you are running on a personal computer or are on a compute node via an interactive job, and have manually set the module stack and required environment variables correctly.\n",
    "\n",
    "- Invoking `run.sh` or a batch script: Often, we don't want to manually set the environment and want the runtime environment to be set automatically based on the compile-time options. This is where `run.sh` or a machine-specific batch script comes in.\n",
    "\n",
    "For this tutorial we'll use the slurm batch scripts located in the `scripts/tutorial/batch` directory. This script sets the SLURM directives, sources the machine file to set the module environment, and submits the job."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1: Hot cylinder in pressure equilibrium\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
