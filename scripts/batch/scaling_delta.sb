#!/bin/bash

# Submit/run script for a KHARMA scaling test on Delta
#SBATCH -J kharma_scaling
#SBATCH --account=bbhr-delta-gpu
#SBATCH -t 30:00
#SBATCH -o out-%j.txt

# Appropriate queues: gpuA100x4 gpuA40x4
# Later: cpu? MI100x8? gpuA100x8?
#SBATCH -p gpuA100x4
#SBATCH -N 32

# Nodes we want
#SBATCH --partition=gpuA100x4
#SBATCH --gpus-per-node=4
#SBATCH --tasks-per-node=4
# OR
##SBATCH --partition=gpuA100x8
##SBATCH --gpus-per-node=8
##SBATCH --tasks-per-node=8

# Node options
# 8-way nodes are 2 sockets, so this is constant
#SBATCH --cpus-per-task=16
# ALWAYS reserve full nodes to mitigate memory leaks
#SBATCH --exclusive
#SBATCH --mem=0

DO_STRONG=true
DO_WEAK=true

KHARMA_DIR=$(dirname "$(readlink -f "$0")")/../..

# Global options
export OMP_PROC_BIND=spread
export OMP_PLACES=threads

# Strong scaling.  Possibly not optimal due to requiring cubic meshblocks
if [[ $DO_STRONG == "true" ]]; then
  for size in 256 512 1024
  do
    for tpn in 4
    do
      # Else for running in dev jobs
      export SLURM_NTASKS_PER_NODE=$tpn
      export IBRUN_TASKS_PER_NODE=$tpn
      # SLURM schedules us on all CPUs, which is nearly always what we want with KHARMA
      # This may one day not be true for Stampede2
      export OMP_NUM_THREADS=$(( $SLURM_CPUS_ON_NODE / $SLURM_NTASKS_PER_NODE ))

      nodes=1
      while (( $nodes <= $SLURM_NNODES ))
      do
        np=$(( $nodes * $tpn ))

        nm=1
        div=1
        while (( $nm < $np ))
        do
          nm=$(( $nm * 8 ))
          div=$(( $div * 2 ))
        done
        msize=$(( $size / $div ))

        echo "cycle=100 Running $size cubed problem with KHARMA on $nodes nodes with $tpn tasks each (blocksize $msize)"

        srun -n $np $KHARMA_DIR/kharma.cuda -i $KHARMA_DIR/pars/scaling_torus.par parthenon/time/nlim=102 \
                                             parthenon/mesh/nx1=$size parthenon/mesh/nx2=$size parthenon/mesh/nx3=$size \
                                             parthenon/meshblock/nx1=$msize parthenon/meshblock/nx2=$msize parthenon/meshblock/nx3=$msize

        nodes=$(( $nodes * 2 ))

      done
    done
  done
fi

# Weak scaling
if [[ $DO_WEAK == "true" ]]; then
  for size in 64 128
  do
    for tpn in 4
    do
      # Else for running in dev jobs
      export SLURM_NTASKS_PER_NODE=$tpn
      export IBRUN_TASKS_PER_NODE=$tpn
      # SLURM schedules us on all CPUs, which is nearly always what we want with KHARMA  
      # This may one day not be true for Stampede2
      export OMP_NUM_THREADS=$(( $SLURM_CPUS_ON_NODE / $SLURM_NTASKS_PER_NODE ))

      nodes=1
      while (( $nodes <= $SLURM_NNODES ))
      do
        np=$(( $nodes * $tpn ))

        mul1=1
        mul2=1
        mul3=1
        if (( $np >= 2 )); then
          mul3=$(( $mul3 * 2 ))
        fi
        if (( $np >= 4 )); then 
          mul2=$(( $mul2 * 2 ))
        fi
        if (( $np >= 8 )); then 
          mul1=$(( $mul1 * 2 ))
        fi
        if (( $np >= 16 )); then 
          mul3=$(( $mul3 * 2 ))
        fi
        if (( $np >= 32 )); then 
          mul2=$(( $mul2 * 2 ))
        fi
        if (( $np >= 64 )); then 
          mul1=$(( $mul1 * 2 ))
        fi
        if (( $np >= 128 )); then 
          mul3=$(( $mul3 * 2 ))
        fi
        if (( $np >= 256 )); then 
          mul2=$(( $mul2 * 2 ))
        fi
        if (( $np >= 512 )); then
          mul1=$(( $mul1 * 2 ))
        fi
        tsize1=$(( $mul1 * $size ))
        tsize2=$(( $mul2 * $size ))
        tsize3=$(( $mul3 * $size ))
        nblock=$(( $mul1 * $mul2 * $mul3 ))
        echo "cycle=100 Running $size per node problem with KHARMA on $nodes nodes with $tpn tasks each (total size ${tsize1}x${tsize2}x${tsize3}, $nblock blocks)"

        srun -n $np $KHARMA_DIR/kharma.cuda -i $KHARMA_DIR/pars/scaling_torus.par parthenon/time/nlim=102 \
                                             parthenon/mesh/nx1=$tsize1 parthenon/mesh/nx2=$tsize2 parthenon/mesh/nx3=$tsize3 \
                                             parthenon/meshblock/nx1=$size parthenon/meshblock/nx2=$size parthenon/meshblock/nx3=$size

        nodes=$(( $nodes * 2 ))

      done
    done
  done
fi
