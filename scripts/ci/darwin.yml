# Continuous Integration testing for KHARMA
# a.k.a did we break the basics?
# This version run on LANL Darwin
# See .gitlab-ci-docker.yml for a generic version,
# which can be run on any Docker runner w/GPUs

variables:
  GIT_SUBMODULE_STRATEGY: recursive
  SCHEDULER_PARAMETERS: "-N 1 --qos=debug -p volta-x86"
  HOST_ARCH: HSW
  NPROC: ""
  OMP_NUM_THREADS: 28
  OMP_PROC_BIND: "false"
  MPI_EXE: mpirun
  MPI_NUM_PROCS: 2
  HTTP_PROXY: http://proxyout.lanl.gov:8080
  http_proxy: http://proxyout.lanl.gov:8080
  HTTPS_PROXY: http://proxyout.lanl.gov:8080
  https_proxy: http://proxyout.lanl.gov:8080
  NO_PROXY: lanl.gov,localhost,127.0.0.1,0.0.0.0,::1
  no_proxy: lanl.gov,localhost,127.0.0.1,0.0.0.0,::1

### DEFAULT TEST BEHAVIOR ###
default:
  id_tokens:
    SITE_ID_TOKEN:
      aud: https://re-git.lanl.gov
  tags:
    - darwin-slurm-shared
  # Load Python
  before_script:
    - micromamba activate pyharm

  # Always keep logs and plots.  Results should be printed to console!
  artifacts:
    when: always
    paths:
      - tests/*/*.png
      - tests/*/*.txt

# Tests can be executed in parallel,
# but be careful about GPU arch
stages:
  - build
  - tests

# Default rules
.default-rules:
  rules:
    - if: $CI_COMMIT_BRANCH == "dev"
      when: always
    - when: manual
  allow_failure: false

# Build, obviously overrides script/artifacts
build:
  extends: .default-rules
  stage: build
  before_script:
    - echo "Skipping pyharm install in build."
  script:
    # CUDA 12.2+ doesn't like EMHD
    - ./make.sh clean cuda120 gcc volta
  artifacts:
    paths:
      - kharma.*
      - make_args

# Run all tests in parallel
tests:
  extends: .default-rules
  stage: tests
  script:
    - cd tests/$TEST
    - ./run.sh
  parallel:
    matrix:
      - TEST: [all_pars, anisotropic_conduction, bondi, bondi_viscous, bz_monopole, conducting_atmosphere,
               emhdmodes, mhdmodes, mhdmodes_smr, noh, regrid, reinit, resize, restart, tilt_init, torus_sanity]

